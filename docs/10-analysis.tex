\section{Аналитическая часть}

В данном разделе <...>. \\

\subsection{Предпосылки}\label{prerequisites}""

В последнее десятилетие центральное процессорное устройство -- ЦПУ (англ. central processing unit -- CPU \cite{cpu})  достигли своей пиковой тактовой частоты -- около 5 Ггц, и этот предел будет преодолён ещё не скоро \cite{cpu_pick}. Из-за того что ЦПУ стали настолько быстрыми, становится нередка ситуация, когда процессор не выполняет инструкции, а ждёт, пока данные переместятся с диска в оперативное запоминающее устройство -- ОЗУ (англ. random access memory -- RAM \cite{ram}) (или наоборот) \cite{in-kernel-memory-compression}. Так, например, скорость работы системы с мощным ЦПУ, но с маленьким количеством ОЗУ может быть маленькой -- несмотря на быстроту, ЦПУ будет часто будет ожидать подсистему ввода/вывода.\\

\subsection{Способы увеличения количества оперативной памяти}""

Проблему объема оперативной памяти компьютера можно решить увеличив количество планок ОЗУ. Но, у данного подхода есть свои минусы:

\begin{itemize}
	\item электроэнергия -- каждая новая установленная планка увеличивает потребление энергии компьютера \cite{increasing-ram-bad};
	\item физические ограничения -- количество слотов для планок на материнской плате ограничено;
	\item стоимость -- планка стоит денег.
\end{itemize}

Альтернативным решением является использование системы подкачки страниц (англ. paging \cite{paging}) -- специальный механизм операционный системы, при котором отдельные фрагменты памяти (мало используемые или полностью не активные) перемещаются из оперативной памяти во вторичной хранилище, например, на жёсткий диск или другой внешний накопитель. Несмотря на то что количество ОЗУ в таком случае увеличивается, доступ к таким участкам памяти замедляется -- системе приходится работать (читать и писать) с внешним запоминающим устройством, а такие устройства работают значительно медленнее ОЗУ \cite{ssd-hdd-speed}.

Ещё одним решением является сжатие данных прямо в оперативной памяти. Данный подход выигрывает у первого рассмотренного решения -- он реализуется программно и не требует закупки дополнительных планок ОЗУ. Так же, этот подход выигрывает и у второго рассмотренного решения -- сжатие не требует работы с внешним накопителем, за счёт чего скорость обработки данных увеличивается. Но сжатие данных так же имеет свои минусы, главным из которых является потребность в вычислительных ресурсах -- ЦПУ должен выполнять какую-то работу. Но, как было описано в разделе \ref{prerequisites}, обычно ЦПУ как раз простаивает и не выполняет никакой работы, ожидая ввод/вывод.\\

\subsection{Сжатие данных}""\

Сжатие основано на устранение избыточности, которая содержится в исходных данных. Часто повторяющиеся фрагменты данных заменяются другими более короткими фрагментами. Так, например, набор символов \texttt{abc def abc jhf abc} можно преобразовать в \texttt{x def x jhf x}, произведя замену символов \texttt{abc} на символ \texttt{x}.

Все методы сжатия данных делятся на два класса: без потерь и с потерями. Сжатие данных без потерь позволяет полностью восстановить сжатые данные, в отличии от сжатия с потерями. Первый вариант чаще всего используют для сжатия текстовых данных и компьютерных программ, а сжатие с потерями используют для сокращения аудио- или видеоданных -- для таких данных не требуется полное соответствие исходным данным. Алгоритмы сжатия данных с потерями обладают большей эффективностью, чем алгоритмы сжатия без потерь \cite{lossless-compression}.

\textbf{<тут написать про степень сжатия>}\\

\subsubsection{Требования к алгоритмам сжатия}""\

К алгоритмам сжатия могут применяться несколько требований:

\begin{itemize}
	\item скорость сжатия;
	\item скорость декомпрессии;
	\item степень сжатия;
	\item эффективность программной реализации.
\end{itemize}

Для каждой конкретной задачи будут важны одни требования и менее важны другие. Так, например, для сжатия больших видеоданных с их последующим хранением, важнее будет степень сжатия данных, а не скорость работы алгоритма.\\

\subsection{Сжатие памяти в ядре Linux}""\

Ядро Linux \cite{linux} - ядро операционной системы с открытым исходным кодом, распространяющееся как свободное программное обеспечение. Именно из-за этого в данной \textbf{<научной-исследовательской надо писать или нет?>} работе будет рассмотрено сжатие оперативной памяти в ядре Linux.

Для сжатия данных в оперативной памяти, ядро берёт последовательность байтов в памяти, сжимает их, записывает сжатую версию обратно в ОЗУ и хранит их до тех пор, пока эти данные не потребуются системе. Пока данные находятся в сжатом состоянии, система не может прочитать или записать какие-либо отдельные байты из этой сжатой последовательности. Когда данные потребуется системе вновь, система распаковывает сжатую последовательность.

Современные алгоритмы могут сжимать любое количество последовательных байт. Несмотря на это, в ядре удобно использовать фиксированную единицу сжатия памяти. Единицей хранения в ядре была выбрана страница памяти (англ. memory page \cite{memory-page}) -- фиксированная константа \texttt{PAGE\_SIZE}, которая на большинстве современных архитектур, поддерживаемых Linux, составляет 4 Кб \cite{4kb-page-size}.

Для достижения высокой степени сжатия требуется выполнение большого количества команд ЦПУ, тогда как менее эффективное сжатие может выполняться быстрее. В ядре необходимо добиться баланса между временем и степенью сжатия. Кроме того, важно чтобы выбор алгоритма оставался гибким. Например для выполнения одной задачи подойдёт один алгоритм сжатия, а для второй другой.

Из-за того что размер страницы достаточно большой (4 Кб), сжатие и распаковка данных -- достаточно дорогостоящие операции, поэтому необходимо ограничить количество этих операций. Нужно тщательно выбирать, какие страницы стоит сжимать, а какие нет. Алгоритм, реализованный в ядре Linux, определяющий какие страницы нужно сжимать, выбирает те страницы, которые вероятно будут использоваться снова, но вряд ли будут использоваться в ближайшем будущем \cite{in-kernel-memory-compression}. Такая реализация позволяет не тратить всё время ЦПУ на многократное сжатие и распаковку страниц. Кроме того, необходимо чтобы ядро могло идентифицировать сжатую страницу -- иначе её невозможно найти и распаковать.

Размер страницы, к которой был применён алгоритм сжатия зависит от данных на исходной странице и его трудно предсказать. Степень сжатия страницы описывается следующей формулой (\ref{fig:page-compressing}):

\begin{equation}\label{fig:page-compressing}
	compression\ ratio = \frac{PAGE\_SIZE}{zsize}
\end{equation}
где \texttt{PAGE\_SIZE} размер страницы памяти в системе, а \texttt{zsize} -- размер сжатой страницы. 

Обычно размер сжатой страницы меньше чем \texttt{PAGE\_SIZE}, поэтому, обычно, коэффициент сжатия меньше единицы. Но, в некоторых случаях, коэффициент сжатия может быть больше единицы, и для решения этой проблемы необходимо, чтобы алгоритм реализованный в ядре мог найти выход из такой ситуации.

\subsubsection{Модуль ядра zram}

\pagebreak
